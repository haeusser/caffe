{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Visualizing classes with GoogLeNet\n",
    "\n",
    "This is an ipython notebook to generate visualizations of classes with GoogLeNet, for some more info refer to [this blogpost](http://auduno.com/post/125362849838/visualizing-googlenet-classes), and for some examples of generated images see [this](https://goo.gl/photos/8qcvjnYBQVSGG2eN6) album of highlights or [this](https://goo.gl/photos/FfsZZektqpZkdDnKA) album of all 1000 imagenet classes.\n",
    "\n",
    "To run this code, you'll need an installation of Caffe with built pycaffe libraries, as well as the python libraries numpy, scipy and PIL. For instructions on how to install Caffe and pycaffe, refer to the installation guide [here](http://caffe.berkeleyvision.org/installation.html). Before running the ipython notebooks, you'll also need to download the [bvlc_googlenet model](https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet), and modify the variables ```pycaffe_root``` to refer to the path of your pycaffe installation (if it's not already in your python path) and ```model_path``` to refer to the path of the googlenet caffe model. Also uncomment the line that enables GPU mode if you have built Caffe with GPU-support and a suitable GPU available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports and basic notebook setup\n",
    "from cStringIO import StringIO\n",
    "import numpy as np\n",
    "import os,re,random\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "import sys\n",
    "from IPython.display import clear_output, Image, display\n",
    "from scipy.misc import imresize\n",
    "\n",
    "pycaffe_root = \"../../python\" # substitute your path here\n",
    "sys.path.insert(0, pycaffe_root)\n",
    "import caffe\n",
    "\n",
    "model_name = \"AlexNetFER\"\n",
    "os.chdir(\"../../\")\n",
    "model_path = 'models/finetune_fer_5_classes/' # substitute your path here\n",
    "net_fn   = model_path + 'deploy.prototxt'\n",
    "param_fn = model_path + 'new_finetune_fer_iter_custom_dataset_iter_74000.caffemodel'\n",
    "mean = np.float32([104.0, 117.0, 123.0])\n",
    "\n",
    "caffe.set_mode_gpu() # uncomment this if gpu processing is available\n",
    "net = caffe.Classifier(net_fn, param_fn,\n",
    "                       mean = mean, # ImageNet mean, training set dependent\n",
    "                       channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n",
    "                       \n",
    "# a couple of utility functions for converting to and from Caffe's input image layout\n",
    "def preprocess(net, img):\n",
    "    return np.float32(np.rollaxis(img, 2)[::-1]) #- net.transformer.mean['data']\n",
    "def deprocess(net, img):\n",
    "    #return np.dstack((img + net.transformer.mean['data'])[::-1])\n",
    "    return np.dstack((img)[::-1])\n",
    "\n",
    "def blur(img, sigma):\n",
    "    if sigma > 0:\n",
    "        img[0] = nd.filters.gaussian_filter(img[0], sigma, order=0)\n",
    "        img[1] = nd.filters.gaussian_filter(img[1], sigma, order=0)\n",
    "        img[2] = nd.filters.gaussian_filter(img[2], sigma, order=0)\n",
    "    return img\n",
    "\n",
    "def showarray(a, f, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the main gradient ascent functions. Note that these are based on the [deepdream code](https://github.com/google/deepdream/blob/master/dream.ipynb) published by Google as well as [this code](https://github.com/kylemcdonald/deepdream/blob/master/dream.ipynb) by Kyle McDonald."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_step(net, step_size=1.5, end='inception_4c/output', clip=True, focus=None, sigma=None):\n",
    "    '''Basic gradient ascent step.'''\n",
    "\n",
    "    src = net.blobs['data'] # input image is stored in Net's 'data' blob\n",
    "    \n",
    "    dst = net.blobs[end]\n",
    "    net.forward(end=end)\n",
    "\n",
    "    one_hot = np.zeros_like(dst.data)\n",
    "    one_hot.flat[focus] = 1.\n",
    "    dst.diff[:] = one_hot\n",
    "\n",
    "    net.backward(start=end)\n",
    "    g = src.diff[0]\n",
    "    #print g\n",
    "    \n",
    "    src.data[:] += step_size/np.abs(g).mean() * g\n",
    "\n",
    "    #if clip:\n",
    "    #    bias = net.transformer.mean['data']\n",
    "    #    src.data[:] = np.clip(src.data, -bias, 255-bias) \n",
    "        \n",
    "    src.data[0] = blur(src.data[0], sigma)\n",
    "    \n",
    "    # reset objective for next step\n",
    "    dst.diff.fill(0.)\n",
    "\n",
    "def deepdraw(net, base_img, octaves, random_crop=True, visualize=True, focus=None,\n",
    "    clip=True, **step_params):\n",
    "    \n",
    "    # prepare base image\n",
    "    image = preprocess(net, base_img) # (3,224,224)\n",
    "    \n",
    "    # get input dimensions from net\n",
    "    w = net.blobs['data'].width\n",
    "    h = net.blobs['data'].height\n",
    "    \n",
    "    print \"starting drawing\"\n",
    "    src = net.blobs['data']\n",
    "    src.reshape(1,3,h,w) # resize the network's input image size\n",
    "    for e,o in enumerate(octaves):\n",
    "        if 'scale' in o:\n",
    "            # resize by o['scale'] if it exists\n",
    "            image = nd.zoom(image, (1,o['scale'],o['scale']))\n",
    "        _,imw,imh = image.shape\n",
    "        \n",
    "        # select layer\n",
    "        layer = o['layer']\n",
    "\n",
    "        for i in xrange(o['iter_n']):\n",
    "            if imw > w:\n",
    "                if random_crop:\n",
    "                    # randomly select a crop \n",
    "                    #ox = random.randint(0,imw-224)\n",
    "                    #oy = random.randint(0,imh-224)\n",
    "                    mid_x = (imw-w)/2.\n",
    "                    width_x = imw-w\n",
    "                    ox = np.random.normal(mid_x, width_x*0.3, 1)\n",
    "                    ox = int(np.clip(ox,0,imw-w))\n",
    "                    mid_y = (imh-h)/2.\n",
    "                    width_y = imh-h\n",
    "                    oy = np.random.normal(mid_y, width_y*0.3, 1)\n",
    "                    oy = int(np.clip(oy,0,imh-h))\n",
    "                    # insert the crop into src.data[0]\n",
    "                    src.data[0] = image[:,ox:ox+w,oy:oy+h]\n",
    "                else:\n",
    "                    ox = (imw-w)/2.\n",
    "                    oy = (imh-h)/2.\n",
    "                    src.data[0] = image[:,ox:ox+w,oy:oy+h]\n",
    "            else:\n",
    "                ox = 0\n",
    "                oy = 0\n",
    "                src.data[0] = image.copy()\n",
    "                \n",
    "            #print src.data\n",
    "\n",
    "            sigma = o['start_sigma'] + ((o['end_sigma'] - o['start_sigma']) * i) / o['iter_n']\n",
    "            step_size = o['start_step_size'] + ((o['end_step_size'] - o['start_step_size']) * i) / o['iter_n']\n",
    "            \n",
    "            make_step(net, end=layer, clip=clip, focus=focus, \n",
    "                      sigma=sigma, step_size=step_size)\n",
    "\n",
    "            if visualize:\n",
    "                vis = deprocess(net, src.data[0])\n",
    "                if not clip: # adjust image contrast if clipping is disabled\n",
    "                    vis = vis*(255.0/np.percentile(vis, 99.98))\n",
    "                if i % 1 == 0:\n",
    "                    showarray(vis,\"./filename\"+str(i)+\".jpg\")\n",
    "            \n",
    "            #if i % 10 == 0:\n",
    "            #    print 'finished step %d in octave %d' % (i,e)\n",
    "            \n",
    "            # insert modified image back into original image (if necessary)\n",
    "            image[:,ox:ox+w,oy:oy+h] = src.data[0]\n",
    "        \n",
    "        print \"octave %d image:\" % e\n",
    "        showarray(deprocess(net, image),\"./octave_\"+str(e)+\".jpg\")\n",
    "            \n",
    "    # returning the resulting image\n",
    "    return deprocess(net, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the class visualizations\n",
    "\n",
    "The ```octaves``` list determines in which order we optimize layers, as well as how many iterations and scaling on each octave. For each octave, parameters are:\n",
    "* ```layer``` : which layer to optimize\n",
    "* ```iter_n``` : how many iterations\n",
    "* ```scale``` : by what factor (if any) to scale up the base image before proceeding\n",
    "* ```start_sigma``` : the initial radius of the gaussian blur\n",
    "* ```end_sigma``` : the final radius of the gaussian blur\n",
    "* ```start_step_size``` : the initial step size of the gradient ascent\n",
    "* ```end_step_size``` : the final step size of the gradient ascent\n",
    "\n",
    "The choice of octave parameters below will give decent images, and is the one used for visualizations in the blogpost. However, the choice of parameters was a bit arbitrary, so feel free to experiment. Note that generating an image will take around 1 minute with GPU-enabled Caffe, or 10-15 minutes if you're running purely on CPU, depending on your computer performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting drawing\n",
      "octave 0 image:\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\nhooqDOQUUUUiD//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-501e545aada6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# generate class visualization via octavewise gradient ascent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         gen_image = deepdraw(net, gen_image, octaves, focus=imagenet_class, \n\u001b[1;32m---> 64\u001b[1;33m                  random_crop=True, visualize=False)\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e0fd2c04d7c8>\u001b[0m in \u001b[0;36mdeepdraw\u001b[1;34m(net, base_img, octaves, random_crop, visualize, focus, clip, **step_params)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             make_step(net, end=layer, clip=clip, focus=focus, \n\u001b[1;32m---> 81\u001b[1;33m                       sigma=sigma, step_size=step_size)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e0fd2c04d7c8>\u001b[0m in \u001b[0;36mmake_step\u001b[1;34m(net, step_size, end, clip, focus, sigma)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#    src.data[:] = np.clip(src.data, -bias, 255-bias)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# reset objective for next step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-10b09044f609>\u001b[0m in \u001b[0;36mblur\u001b[1;34m(img, sigma)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/filters.pyc\u001b[0m in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[1;32m--> 305\u001b[1;33m                               mode, cval, truncate)\n\u001b[0m\u001b[0;32m    306\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/filters.pyc\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/filters.pyc\u001b[0m in \u001b[0;36mcorrelate1d\u001b[1;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[1;32m--> 144\u001b[1;33m                           origin)\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# these octaves determine gradient ascent steps\n",
    "octaves = [\n",
    "    {\n",
    "        'layer':'fc8_fer',\n",
    "        'iter_n':300,\n",
    "        'start_sigma':3.5,\n",
    "        'end_sigma':1.5,\n",
    "        'start_step_size':18.*0.5,\n",
    "        'end_step_size':11.*0.25\n",
    "    },\n",
    "    {\n",
    "        'layer':'fc8_fer',\n",
    "        'iter_n':300,\n",
    "        'start_sigma':2.5,\n",
    "        'end_sigma':1.,\n",
    "        'start_step_size':12,\n",
    "        'end_step_size':4\n",
    "    },\n",
    "    {\n",
    "        'layer':'fc8_fer',\n",
    "        'iter_n':300,\n",
    "        'start_sigma':1.8,\n",
    "        'end_sigma':0.5,\n",
    "        'start_step_size':8.,\n",
    "        'end_step_size':2.\n",
    "    },\n",
    "    {\n",
    "        'layer':'fc8_fer',\n",
    "        'iter_n':300,\n",
    "        'start_sigma':1.8,\n",
    "        'end_sigma':0.5,\n",
    "        'start_step_size':8.,\n",
    "        'end_step_size':2.\n",
    "    },\n",
    "    {\n",
    "        'layer':'fc8_fer',\n",
    "        'iter_n':300,\n",
    "        'start_sigma':1.8,\n",
    "        'end_sigma':0.5,\n",
    "        'start_step_size':8.,\n",
    "        'end_step_size':2.\n",
    "    }\n",
    "]\n",
    "\n",
    "# get original input size of network\n",
    "original_w = net.blobs['data'].width\n",
    "original_h = net.blobs['data'].height\n",
    "\n",
    "# the background color of the initial image\n",
    "background_color = np.float32([200.0, 200.0, 200.0])\n",
    "# generate initial random image\n",
    "gen_image = np.random.normal(background_color, 8, (original_w, original_h, 3))\n",
    "\n",
    "# which imagenet class to visualize\n",
    "imagenet_class = em\n",
    "\n",
    "# generate class visualization via octavewise gradient ascent\n",
    "gen_image = deepdraw(net, gen_image, octaves, focus=imagenet_class, \n",
    "                 random_crop=True, visualize=False)\n",
    "\n",
    "# save image\n",
    "#img_fn = '_'.join([model_name, \"deepdraw\", str(imagenet_class)+'.png'])\n",
    "#PIL.Image.fromarray(np.uint8(gen_image)).save('./' + img_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This choice of octave parameters tends to give more coherent images, but has a little bit less detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
